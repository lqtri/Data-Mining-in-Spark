{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l13ddSL2RMIF"
      },
      "source": [
        "# **LAB 04 - Lập trình Spark với Python**\n",
        "\n",
        "**Thông tin các thành viên**\n",
        "\n",
        "MSSV | Họ tên \n",
        "---|---\n",
        "Đỗ Nhật Toàn | 19120688 \n",
        "Lê Quốc Trí | 19120691 \n",
        "Đào Xuân Tùng | 19120707 \n",
        "Đinh Nhật Tường | 19120709 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Khởi tạo Spark"
      ],
      "metadata": {
        "id": "smUJaT5tgYZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "4Lz33x2reTn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b87077-a7b0-4f32-d68f-9a79ed1d1946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeyAKBgwo05o"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehQVcFjFxZ4t"
      },
      "outputs": [],
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTRRiDNrp-s9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a30b48b-d0bb-47a7-8fc6-861770656e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!tar xzf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un07WvpcqOyM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktKgWqqirVGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b554936-21eb-4988-ed62-930238ca755c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 27 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 50.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=a9ac058ed017d9f2ee38e22a3b96904600f8e5cc60e80641d992ffbe0cc1b226\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ywH5jP2yz89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "b4c724c2-d36f-4f2c-d20d-bad93003df8a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0f402ca32da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local[*]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# dataset link: https://drive.google.com/file/d/1qakfZ5h7wJzZpjdGzs7Nv0kHeMGFv-RV/view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     getattr(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sparkContext, jsparkSession, options)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 )\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mjsparkSession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             getattr(getattr(self._jvm, \"SparkSession$\"), \"MODULE$\").applyModifiableSettings(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1586\u001b[0;31m             answer, self._gateway_client, None, self._fqn)\n\u001b[0m\u001b[1;32m   1587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n",
            "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:\npy4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)\n\tat py4j.Gateway.invoke(Gateway.java:237)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# dataset link: https://drive.google.com/file/d/1qakfZ5h7wJzZpjdGzs7Nv0kHeMGFv-RV/view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9PmMdphWk8t"
      },
      "outputs": [],
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1qakfZ5h7wJzZpjdGzs7Nv0kHeMGFv-RV\" -O \"Lab04-Data.zip\"\n",
        "!unzip \"/content/Lab04-Data.zip\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PPXbnqws4FY"
      },
      "source": [
        "# **Bài 1 - Khai thác mẫu phổ biến và luật kết hợp**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Đọc dữ liệu vào PySpark và tiền xử lý dữ liệu**"
      ],
      "metadata": {
        "id": "znxCb89IV-8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO9W5cIkW5WZ"
      },
      "outputs": [],
      "source": [
        "order_df = spark.read.csv(\"Lab04-Data/orders.csv\", header='True')\n",
        "products_df = spark.read.csv(\"Lab04-Data/products.csv\", header='True')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuXrnIEiXfLq"
      },
      "outputs": [],
      "source": [
        "order_df.printSchema()\n",
        "products_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqN44NwYX5Dz"
      },
      "outputs": [],
      "source": [
        "order_df.show(5)\n",
        "products_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Để thực một số phương thức tiền xử lý dữ liệu, ta sử dụng các fuctions của PySpark SQL.\n",
        "- Để có thể lấy được tên các sản phẩm (products) của từng mã order ta thực hiện phép join 2 bảng có điều kiện, sử dụng <em>GroupBy</em> để thao thác trên từng order id, ứng với mỗi order id ta sử dụng phương thức <em>collect_list</em> trên thuộc tính products để tạo ra danh sách các sản phẩm."
      ],
      "metadata": {
        "id": "gf2gk2AfWT2y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBMdORfOYth7"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvk6789QcmeH"
      },
      "outputs": [],
      "source": [
        "df = order_df.join(products_df,order_df['product_id']==products_df['product_id'])\\\n",
        "      .groupBy('order_id')\\\n",
        "      .agg(f.collect_list('product_name').alias('products'))\\\n",
        "      .orderBy('order_id')\\\n",
        "      .select('order_id','products')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmBd-_bzkYu1"
      },
      "outputs": [],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "ReQvsCtYKztU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Áp dụng giải thuật khai thác mẫu phổ biến và luật kết hợp trong gói pyspark.ml.fpm**"
      ],
      "metadata": {
        "id": "8N8r1UYQXro1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcSf7pSt39qh"
      },
      "source": [
        "Khởi tạo mô hình FPGrowth của PySpark qua thư viện <em>pyspark.ml.fpm</em> và chạy trên tập dữ liệu đã tiền xử lý"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oyu1KRJU0Rbv"
      },
      "outputs": [],
      "source": [
        "import pyspark.ml.fpm as fpm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi tạo FPGrowth với:\n",
        "- minSupport = 0.01\n",
        "- minConfidence = 0.01"
      ],
      "metadata": {
        "id": "jpxtvUQ2LLhJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-qhG47M3OxI"
      },
      "outputs": [],
      "source": [
        "fpg = fpm.FPGrowth(itemsCol='products', minSupport=0.001, minConfidence=0.01)\n",
        "model = fpg.fit(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_cFNEx4nMW"
      },
      "source": [
        "Lấy ra các tập phổ biến từ mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWwS3dgh0sY3"
      },
      "outputs": [],
      "source": [
        "frequent_itemsets = model.freqItemsets\n",
        "frequent_itemsets.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets.count()"
      ],
      "metadata": {
        "id": "BkhBiGakKqZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xem chi tiết các itemsets phổ biến**"
      ],
      "metadata": {
        "id": "ngr0wuONyrI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets.select('items').collect()"
      ],
      "metadata": {
        "id": "oA6D5cfFyubC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw6FBYDu5EB_"
      },
      "source": [
        "**Rút ra các bộ luật**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs5b-Bux44aK"
      },
      "outputs": [],
      "source": [
        "associate_rules = model.associationRules\n",
        "associate_rules.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "associate_rules.count()"
      ],
      "metadata": {
        "id": "JBCV1BCNKZA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xem chi tiết các luật rút ra được**"
      ],
      "metadata": {
        "id": "V86b3w9QzDkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "associate_rules.select('antecedent','consequent').collect()"
      ],
      "metadata": {
        "id": "tolaxPHoYf_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMhyt2LA76K2"
      },
      "source": [
        "**Kết luận** </br>\n",
        "- Với minSupport = 0.001 ta thu được 4444 tập phổ biến trên tổng số 131209 mẫu. Cho ra tỉ lệ tập phổ biến xấp xỉ 0.34%. </br>\n",
        "$→$ Dữ liệu không bị lặp nhiều\n",
        "- Kết hợp tìm các luật với minConfidence = 0.01 ta thu được 5435 luật"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f383Nunj6KhE"
      },
      "source": [
        "**Chạy mô hình trên tập dữ liệu trên với các bộ minSupport và minConfidence khác:**\n",
        "- minSupport = 0.1\n",
        "- minConfidence = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fpg = fpm.FPGrowth(itemsCol='products', minSupport=0.1, minConfidence=0.1)\n",
        "model2 = fpg.fit(df)"
      ],
      "metadata": {
        "id": "9OSejOQMI7K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.freqItemsets.collect()"
      ],
      "metadata": {
        "id": "NSybLgYFJFyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.associationRules.show()"
      ],
      "metadata": {
        "id": "OwDHG6YHJReh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nhận xét:** Khi tăng minSupport lên 0.1, ta chỉ tìm được 2 tập phổ biến là Banana và Bag of Organic Bananas. Với minConfidence = 0.1 thì ta không tìm thấy một luật nào."
      ],
      "metadata": {
        "id": "O8AknJs0JWON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Vấn đề về hình thức của các luật tìm thấy và giải pháp khắc phục** </br>\n",
        "</br>\n",
        "**Nhận xét:** Có thể thấy các vế của bộ luật chỉ gồm 1 item như: <em>Large Lemons $→$ Limes</em> và thiếu đi các luật mà 2 vế gồm nhiều items.</br>\n",
        "$→$ Điều cần lưu ý khi sử dụng FPGrowth trong thư viện học máy của PySpark là các luật được rút ra về phía consequent chỉ có 1 item. </br>\n",
        "\n",
        "**Cách khắc phục:** Sử dụng thư viện **MLxtend** - một trong các thư viện hỗ trợ các công cụ về học máy và khoa học dữ liệu. Dùng **association_rules** để khai thác các luật có minConfience = 0.05 với tập phổ biến ta đã tìm được với minSupport = 0.01"
      ],
      "metadata": {
        "id": "dfTCz9JTzoOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend"
      ],
      "metadata": {
        "id": "TFhhTn8Y4iVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "oi5nmMDA7dsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets_df = frequent_itemsets.toPandas()\n",
        "\n",
        "def get_support(freq,N):\n",
        "  return freq/N"
      ],
      "metadata": {
        "id": "XvJxvPlfG-9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets_temp = pd.DataFrame()\n",
        "frequent_itemsets_temp['support'] = get_support(frequent_itemsets_df['freq'],df.count())\n",
        "frequent_itemsets_temp['itemsets'] = frequent_itemsets_df['items']"
      ],
      "metadata": {
        "id": "Y9PDQcvtIs8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_association_rules = association_rules(frequent_itemsets_temp,metric='confidence',min_threshold=0.01)\n",
        "new_association_rules"
      ],
      "metadata": {
        "id": "5MlWPzJkJPE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau khi tìm lại các luật với minConfidence = 0.01 bởi MLxtend trên tập phổ biến đã tìm được bởi FPGrowth của PySpark với minSupport = 0.001, ta nhận tìm được 6583 luật, nghĩa là có 1148 luật có consequent nhiều hơn 1 items được tìm thấy. </br>\n",
        "</br>\n",
        "**Các luật có consequent nhiều hơn 1 item được thể hiện ở DataFrame bên dưới:**"
      ],
      "metadata": {
        "id": "egtUBsxqPRXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_consequent_size(cons):\n",
        "  return len(cons)\n",
        "new_association_rules['length'] = new_association_rules['consequents'].apply(get_consequent_size)\n",
        "new_association_rules[new_association_rules['length']>1]"
      ],
      "metadata": {
        "id": "DzY4J3TdQ88u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3jPmSWC6iz7"
      },
      "source": [
        "# **Bài 2 - Phân lớp**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIljm_iEBFQt"
      },
      "source": [
        "**1)  Đọc dữ liệu vào Spark và chia dữ liệu thành tập huấn luyện và tập kiểm thử theo tỉ lệ 80:20**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xogn5Vm6m1_"
      },
      "outputs": [],
      "source": [
        "mushroom_df = spark.read.csv(\"Lab04-Data/mushrooms.csv\", header='True')\n",
        "mushroom_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = mushroom_df.randomSplit(weights=[0.8,0.2], seed=100)\n",
        "print(train.count(), test.count())"
      ],
      "metadata": {
        "id": "-Y81W8WAbnyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYIcr_IqBJM2"
      },
      "source": [
        "**2) Xây dựng mô hình decision tree trên tập huấn luyện**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "id": "OEYBZnVSfHnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import OneHotEncoder"
      ],
      "metadata": {
        "id": "d2zx0HQ9B4bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_col = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']"
      ],
      "metadata": {
        "id": "i2AkA3t9AhWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sử dụng One Hot Encoder để chuyển đổi dữ liệu dạng Categories về dạng Index và biến stages dạng list để lưu thứ tự thực thi với pipeline\n",
        "stages = []\n",
        "for col in input_col:\n",
        "    stringIndexer = StringIndexer(inputCol = col, outputCol = col + 'Index')\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[col + \"classVec\"])\n",
        "    stages += [stringIndexer, encoder]\n",
        "\n",
        "# Tạo vector features là các thuộc tính có trên tập dữ liệu (trừ thuọc tính class) và gom dữ liệu các thuộc tính thành vector\n",
        "assemblerInputs = [col + \"classVec\" for col in input_col]\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "\n",
        "#Tạo thuộc tính dạng index cho thuộc tính features vector theo tham số của mô hình Decision Tree yêu cầu\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=2)\n",
        "\n",
        "# Thêm thuộc tính label dạng numberic từ thuộc tính class dạng categories\n",
        "labelIndexer = StringIndexer(inputCol=\"class\", outputCol=\"indexedLabel\")\n",
        "\n",
        "# Thêm vào pipeline\n",
        "stages += [assembler, labelIndexer, featureIndexer]"
      ],
      "metadata": {
        "id": "TopI5RdZSbK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo mô hình Decision Tree với indexedLabel và indexedFeatures\n",
        "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
        "stages += [dt]\n",
        "\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "# Training với pipeline\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Chạy DT trên tập test\n",
        "predictions = model.transform(test)\n",
        "\n",
        "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "y_true = predictions.select(\"indexedLabel\").rdd.flatMap(lambda x: x).collect()\n",
        "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='micro')\n",
        "\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "\n",
        "treeModel = model.stages[-1]\n",
        "print(treeModel)\n",
        "print(\"Test Accuracy = %g\" % (accuracy))\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "print(\"The Confusion Matrix:\\n\" + str(confusionmatrix))\n",
        "\n",
        "print(\"Precision score: \" + str(precision))\n",
        "\n",
        "print(\"Recall score: \" + str(recall))"
      ],
      "metadata": {
        "id": "qbK1COlq9EBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận xét:\n",
        "- Accuracy của mô hình mạng lại khá cao: 0.998141\n",
        "- Dựa vào confusion matrix chỉ có 3/1614 mẫu được dự đoán sai"
      ],
      "metadata": {
        "id": "Edo3zYK9lDGF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8q6YP0DBMr_"
      },
      "source": [
        "**3) Xây dựng mô hình Random Forest trên tập huấn luyện**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "TABXRIsNa6Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stages1 = []\n",
        "for col in input_col:\n",
        "    stringIndexer = StringIndexer(inputCol = col, outputCol = col + 'Index')\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[col + \"classVec\"])\n",
        "    stages1 += [stringIndexer, encoder]\n",
        "\n",
        "assemblerInputs = [c + \"classVec\" for c in input_col]\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=2)\n",
        "labelIndexer = StringIndexer(inputCol=\"class\", outputCol=\"indexedLabel\")\n",
        "\n",
        "stages1 += [assembler, labelIndexer, featureIndexer]"
      ],
      "metadata": {
        "id": "IIMn3Lf9ai6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
        "stages1 += [rf]\n",
        "\n",
        "pipeline = Pipeline(stages=stages1)\n",
        "\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "predictions = model.transform(test)\n",
        "  \n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "y_true = predictions.select(\"indexedLabel\").rdd.flatMap(lambda x: x).collect()\n",
        "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
        "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='micro')\n",
        "\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "\n",
        "print(\"Test Accuracy = %g\" % (accuracy))\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\" + str(confusionmatrix))\n",
        "\n",
        "print(\"Precision score: \" + str(precision))\n",
        "\n",
        "print(\"Recall score: \" + str(recall))"
      ],
      "metadata": {
        "id": "az7XvCXg9FRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận xét:\n",
        "- Accuracy của mô hình khá cao: 0.9758\n",
        "- Có 39/1614 mẫu được dự đoán sai trong tập test"
      ],
      "metadata": {
        "id": "_Q0pyWXJmVAB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjrHGzplBPO4"
      },
      "source": [
        "**4) Đánh giá hai mô hình trên tập kiểm thử**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<em>Decision Tree</em>:</br>\n",
        "    - Thuật toán có độ chính xác 99.8% khi thử nghiệm trên tập test và có tỉ lệ lỗi là 0.2%</br>\n",
        "<em>RandomForest</em>:</br>\n",
        "    - Thuật toán có độ chính xác 98.5% khi thử nghiệm trên tập test và có tỉ lệ lỗi là 2.42%</br>\n",
        "$→$ Đối với tập dữ liệu này, thuật toán Decision Tree cho độ chính xác cao hơn RandomForest nhưng cũng không đáng kể."
      ],
      "metadata": {
        "id": "orXEBEuEYx-o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY4ZDQ_WtI-i"
      },
      "source": [
        "# **Bài 3 - Gom cụm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvqoy8UF6nRa"
      },
      "outputs": [],
      "source": [
        "!unrar x \"/content/Lab04-Data/plants.rar\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E39-kscfBk99"
      },
      "source": [
        "**1) Tiền xử lý dữ liệu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7EJ-aYhBqRZ"
      },
      "outputs": [],
      "source": [
        "plants_df = spark.read.text(\"plants.data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPcD79AMLDt4"
      },
      "outputs": [],
      "source": [
        "plants_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJKfLZ-eIF7U"
      },
      "outputs": [],
      "source": [
        "plants_list = plants_df.select('value').rdd.flatMap(lambda x: x).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYonLPOuKh9B"
      },
      "outputs": [],
      "source": [
        "plants = []\n",
        "positions = []\n",
        "\n",
        "for line in plants_list:\n",
        "  words = line.split(',')\n",
        "  plants.append(words[0])\n",
        "  positions.append(words[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQMnCiTiMnBa"
      },
      "outputs": [],
      "source": [
        "position_list = []\n",
        "for sample in positions:\n",
        "  for p in sample:\n",
        "    if p in position_list:\n",
        "      continue\n",
        "    else:\n",
        "      position_list.append(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdE-0TmXOuEh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['plant'] = pd.DataFrame(plants)\n",
        "for pos in position_list:\n",
        "  pos_col = []\n",
        "  for sample in positions:\n",
        "    if pos in sample:\n",
        "      pos_col.append(1)\n",
        "    else:\n",
        "      pos_col.append(0)\n",
        "  df[pos] = pd.DataFrame(pos_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJU3e_JjPvZj"
      },
      "outputs": [],
      "source": [
        "plants_df = spark.createDataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqJq3InxQqDO"
      },
      "outputs": [],
      "source": [
        "plants_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjRGxprcBqjk"
      },
      "source": [
        "**2) Thực hiện gom cụm các loài thực vật theo vùng địa lý bằng giải thuật k-means và đánh giá kết quả gom cụm bằng ClusteringEvaluator. Thử nghiệm với một số giá trị k**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "XqocKrbAkHd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vecAssembler = VectorAssembler(inputCols=position_list, outputCol=\"features\")\n",
        "new_df = vecAssembler.transform(plants_df)"
      ],
      "metadata": {
        "id": "bM_hjw9OsiD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores=[]\n",
        "evaluator = ClusteringEvaluator(featuresCol='features', \\\n",
        "metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
        "\n",
        "for K in range(2,20):\n",
        "    KMeans_=KMeans(featuresCol='features', k=K)\n",
        "    KMeans_fit=KMeans_.fit(new_df)\n",
        "    KMeans_transform=KMeans_fit.transform(new_df) \n",
        "    evaluation_score=evaluator.evaluate(KMeans_transform)\n",
        "    silhouette_scores.append(evaluation_score)"
      ],
      "metadata": {
        "id": "S6uz7rl-zy4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1,1, figsize =(20,8))\n",
        "ax.plot(range(2,20),silhouette_scores)\n",
        "ax.set_xlabel('Number of clusters')\n",
        "ax.set_ylabel('Silhouette Score')"
      ],
      "metadata": {
        "id": "ZQbeGocq0IaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nhận xét (ClusteringEvaluator):**</br>\n",
        "Ở lần thực thi hiện tại, biểu đồ Clustering Evaluator cho thấy các giá trị $k$ (số cluster) phù hợp với tập dữ liệu này có Silhouette score cao nhất là $k=2,4,6,7,8$ (xếp theo thứ tự giảm dần)</br>\n",
        "Silhouette score: là giá trị tổng thể cho biết các điểm dữ liệu được phân bố vào đúng cụm của nó"
      ],
      "metadata": {
        "id": "zMpr-hMbPz06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clustering với $k=2$**"
      ],
      "metadata": {
        "id": "1jBXr3AWSdsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(k=2, seed=1)\n",
        "model = kmeans.fit(new_df.select('features'))\n",
        "transformed = model.transform(new_df)\n",
        "cluster = transformed.select('plant','prediction')"
      ],
      "metadata": {
        "id": "OeqJWKa7jK0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thống kê số lượng mẫu thuộc các cluster"
      ],
      "metadata": {
        "id": "v05EhQvtpe0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster.groupby('prediction').count().orderBy('prediction').show()"
      ],
      "metadata": {
        "id": "Hp5J-Tbc059d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clustering với $k=4$**"
      ],
      "metadata": {
        "id": "IEhSBkY_USef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(k=4, seed=1)\n",
        "model = kmeans.fit(new_df.select('features'))\n",
        "transformed = model.transform(new_df)\n",
        "cluster = transformed.select('plant','prediction')"
      ],
      "metadata": {
        "id": "4qJyptcHUWMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thống kê số lượng mẫu thuộc các cluster"
      ],
      "metadata": {
        "id": "-HwXPbbJpixZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster.groupby('prediction').count().orderBy('prediction').show()"
      ],
      "metadata": {
        "id": "oHEkZ7gqUZNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hết"
      ],
      "metadata": {
        "id": "UTnCsCRDq5Tf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lab04.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}